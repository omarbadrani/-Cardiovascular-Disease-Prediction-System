{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod√®le de Pr√©diction des Maladies Cardiovasculaires\n",
    "## Pr√©diction robuste avec validation crois√©e et analyse ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulation des donn√©es\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Affichage et visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Mod√®les et m√©triques\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve, auc\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Configuration des visualisations\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement et Exploration des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le dataset de mani√®re cross-platform\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Utiliser un chemin relatif ou une variable d'environnement\n",
    "data_path = Path('datasetCleaned.csv')\n",
    "\n",
    "# Si le fichier n'existe pas au chemin relatif, chercher dans les r√©pertoires courants\n",
    "if not data_path.exists():\n",
    "    possible_paths = [\n",
    "        Path.cwd() / 'datasetCleaned.csv',\n",
    "        Path.cwd().parent / 'datasetCleaned.csv',\n",
    "        Path(__file__).parent / 'datasetCleaned.csv' if '__file__' in dir() else None,\n",
    "    ]\n",
    "    for path in possible_paths:\n",
    "        if path and path.exists():\n",
    "            data_path = path\n",
    "            break\n",
    "\n",
    "print(f'Chemin du dataset: {data_path.resolve()}')\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f'\\n‚úì Dataset charg√© avec succ√®s!')\n",
    "print(f'Dimensions du dataset: {df.shape}')\n",
    "print(f'Nombre de lignes: {df.shape[0]:,}')\n",
    "print(f'Nombre de colonnes: {df.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les premi√®res lignes\n",
    "print('\\nAper√ßu des donn√©es:')\n",
    "print(df.head())\n",
    "\n",
    "# Informations sur les types de donn√©es\n",
    "print('\\nInformations sur les colonnes:')\n",
    "print(df.info())\n",
    "\n",
    "# Statistiques descriptives\n",
    "print('\\nStatistiques descriptives:')\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier les valeurs manquantes\n",
    "print('Valeurs manquantes:')\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() == 0:\n",
    "    print('‚úì Aucune valeur manquante d√©tect√©e')\n",
    "else:\n",
    "    print(missing[missing > 0])\n",
    "\n",
    "# V√©rifier la distribution de la variable cible\n",
    "print('\\nDistribution de la variable cible (cardio):')\n",
    "print(df['cardio'].value_counts())\n",
    "print(f'\\nProportions:')\n",
    "print(df['cardio'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualisation et Analyse Exploratoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser la distribution de la variable cible\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Graphique 1: Compte des classes\n",
    "df['cardio'].value_counts().plot(kind='bar', ax=axes[0], color=['#2ecc71', '#e74c3c'])\n",
    "axes[0].set_title('Distribution de la Maladie Cardiovasculaire', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Maladie Cardiovasculaire')\n",
    "axes[0].set_ylabel('Nombre de patients')\n",
    "axes[0].set_xticklabels(['Non (0)', 'Oui (1)'], rotation=0)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Graphique 2: Pourcentages\n",
    "cardio_pct = df['cardio'].value_counts(normalize=True) * 100\n",
    "axes[1].pie(cardio_pct, labels=['Non atteint', 'Atteint'], autopct='%1.1f%%',\n",
    "            colors=['#2ecc71', '#e74c3c'], startangle=90)\n",
    "axes[1].set_title('Proportion de Maladies Cardiovasculaires', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nBilan:')\n",
    "print(f'Patients sans maladie: {(df[\"cardio\"]==0).sum():,} ({(df[\"cardio\"]==0).sum()/len(df)*100:.1f}%)')\n",
    "print(f'Patients avec maladie: {(df[\"cardio\"]==1).sum():,} ({(df[\"cardio\"]==1).sum()/len(df)*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de corr√©lation\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, cbar_kws={'label': 'Corr√©lation'})\n",
    "plt.title('Matrice de Corr√©lation des Variables', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Afficher les corr√©lations avec la variable cible\n",
    "print('\\nCorr√©lations avec la variable cible (cardio):')\n",
    "target_corr = correlation_matrix['cardio'].sort_values(ascending=False)\n",
    "print(target_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pr√©paration des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©parer les features et la cible\n",
    "# Supposant que 'cardio' est la variable cible\n",
    "X = df.drop(['cardio', 'Unnamed: 0'], axis=1, errors='ignore')\n",
    "y = df['cardio']\n",
    "\n",
    "print(f'Features: {X.shape[1]}')\n",
    "print(f'Nombre d\\'exemples: {X.shape[0]:,}')\n",
    "print(f'\\nColonnes utilis√©es:')\n",
    "print(list(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser les donn√©es en ensembles d'entra√Ænement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f'Ensemble d\\'entra√Ænement: {X_train.shape[0]:,} exemples')\n",
    "print(f'Ensemble de test: {X_test.shape[0]:,} exemples')\n",
    "print(f'\\nDistribution dans l\\'ensemble d\\'entra√Ænement:')\n",
    "print(f'  - N√©gatifs: {(y_train==0).sum():,} ({(y_train==0).sum()/len(y_train)*100:.1f}%)')\n",
    "print(f'  - Positifs: {(y_train==1).sum():,} ({(y_train==1).sum()/len(y_train)*100:.1f}%)')\n",
    "print(f'\\nDistribution dans l\\'ensemble de test:')\n",
    "print(f'  - N√©gatifs: {(y_test==0).sum():,} ({(y_test==0).sum()/len(y_test)*100:.1f}%)')\n",
    "print(f'  - Positifs: {(y_test==1).sum():,} ({(y_test==1).sum()/len(y_test)*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliser les donn√©es (optionnel mais recommand√©)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print('‚úì Donn√©es normalis√©es avec succ√®s')\n",
    "print(f'\\nMoyenne des features (ensemble d\\'entra√Ænement): {X_train_scaled.mean(axis=0).mean():.6f}')\n",
    "print(f'√âcart-type des features (ensemble d\\'entra√Ænement): {X_train_scaled.std(axis=0).mean():.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entra√Ænement du Mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er et entra√Æner le mod√®le Random Forest\n",
    "print('Entra√Ænement du mod√®le Random Forest...')\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "# Entra√Æner sur les donn√©es originales (Random Forest n'a pas besoin de normalisation)\n",
    "model.fit(X_train, y_train)\n",
    "print('‚úì Mod√®le entra√Æn√© avec succ√®s!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Validation Crois√©e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effectuer une validation crois√©e stratifi√©e\n",
    "print('Ex√©cution de la validation crois√©e stratifi√©e (5 folds)...\\n')\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# M√©triques √† calculer\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1',\n",
    "    'roc_auc': 'roc_auc'\n",
    "}\n",
    "\n",
    "# Validation crois√©e\n",
    "cv_results = cross_validate(model, X_train, y_train, cv=skf, scoring=scoring, return_train_score=True)\n",
    "\n",
    "# Afficher les r√©sultats\n",
    "print('R√©sultats de la Validation Crois√©e (5 folds):')\n",
    "print('='*60)\n",
    "\n",
    "for metric in scoring.keys():\n",
    "    train_scores = cv_results[f'train_{metric}']\n",
    "    test_scores = cv_results[f'test_{metric}']\n",
    "    \n",
    "    print(f'\\n{metric.upper()}:')\n",
    "    print(f'  Train: {train_scores.mean():.4f} (+/- {train_scores.std():.4f})')\n",
    "    print(f'  Test:  {test_scores.mean():.4f} (+/- {test_scores.std():.4f})')\n",
    "    print(f'  D√©tails: {[f\"{s:.4f}\" for s in test_scores]}')\n",
    "\n",
    "print('\\n' + '='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser les r√©sultats de la validation crois√©e\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "colors = ['#3498db', '#e74c3c']\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    train_scores = cv_results[f'train_{metric}']\n",
    "    test_scores = cv_results[f'test_{metric}']\n",
    "    folds = np.arange(1, len(test_scores) + 1)\n",
    "    \n",
    "    axes[idx].plot(folds, train_scores, 'o-', label='Train', color=colors[0], linewidth=2, markersize=8)\n",
    "    axes[idx].plot(folds, test_scores, 's-', label='Test', color=colors[1], linewidth=2, markersize=8)\n",
    "    axes[idx].set_xlabel('Fold')\n",
    "    axes[idx].set_ylabel(metric.capitalize())\n",
    "    axes[idx].set_title(f'{metric.capitalize()} par Fold')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "    axes[idx].set_ylim([0, 1.05])\n",
    "\n",
    "# Supprimer le dernier subplot vide\n",
    "fig.delaxes(axes[5])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. √âvaluation du Mod√®le sur l'Ensemble de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faire des pr√©dictions sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculer les m√©triques\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print('M√©triques de Performance sur l\\'Ensemble de Test')\n",
    "print('='*50)\n",
    "print(f'Accuracy (Exactitude):  {accuracy:.4f}')\n",
    "print(f'Precision (Pr√©cision):  {precision:.4f}')\n",
    "print(f'Recall (Sensibilit√©):   {recall:.4f}')\n",
    "print(f'F1-Score:               {f1:.4f}')\n",
    "print(f'ROC-AUC:                {roc_auc:.4f}')\n",
    "print('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('\\nMatrice de Confusion:')\n",
    "print(cm)\n",
    "print(f'\\nInterpr√©tation:')\n",
    "print(f'  Vrais N√©gatifs (TN):      {cm[0,0]:,}')\n",
    "print(f'  Faux Positifs (FP):       {cm[0,1]:,}')\n",
    "print(f'  Faux N√©gatifs (FN):       {cm[1,0]:,}')\n",
    "print(f'  Vrais Positifs (TP):      {cm[1,1]:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rapport de classification d√©taill√©\n",
    "print('\\nRapport de Classification D√©taill√©:')\n",
    "print('='*60)\n",
    "print(classification_report(y_test, y_pred, \n",
    "                          target_names=['Non-Atteint', 'Atteint'],\n",
    "                          digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyse ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer la courbe ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc_score_value = auc(fpr, tpr)\n",
    "\n",
    "# Visualiser la courbe ROC\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Graphique 1: Courbe ROC\n",
    "axes[0].plot(fpr, tpr, color='#3498db', lw=2.5, label=f'ROC Curve (AUC = {roc_auc_score_value:.4f})')\n",
    "axes[0].plot([0, 1], [0, 1], color='#e74c3c', lw=2, linestyle='--', label='Al√©atoire (AUC = 0.5000)')\n",
    "axes[0].set_xlim([0.0, 1.0])\n",
    "axes[0].set_ylim([0.0, 1.05])\n",
    "axes[0].set_xlabel('Taux de Faux Positifs')\n",
    "axes[0].set_ylabel('Taux de Vrais Positifs')\n",
    "axes[0].set_title('Courbe ROC - Analyse AUC')\n",
    "axes[0].legend(loc='lower right', fontsize=11)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Graphique 2: Matrice de confusion\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1], \n",
    "            xticklabels=['Non-Atteint', 'Atteint'],\n",
    "            yticklabels=['Non-Atteint', 'Atteint'],\n",
    "            cbar_kws={'label': 'Nombre'})\n",
    "axes[1].set_title('Matrice de Confusion')\n",
    "axes[1].set_ylabel('Vrai Label')\n",
    "axes[1].set_xlabel('Pr√©diction')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Importance des Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir l'importance des features\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print('Importance des Features:')\n",
    "print('='*50)\n",
    "for idx, row in feature_importance.iterrows():\n",
    "    print(f'{row[\"feature\"]:15s} : {row[\"importance\"]:.4f}')\n",
    "print('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser l'importance des features\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "colors_gradient = plt.cm.viridis(np.linspace(0, 1, len(feature_importance)))\n",
    "bars = ax.barh(feature_importance['feature'], feature_importance['importance'], color=colors_gradient)\n",
    "\n",
    "ax.set_xlabel('Importance', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Importance des Features dans le Mod√®le', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Ajouter les valeurs sur les barres\n",
    "for i, (bar, val) in enumerate(zip(bars, feature_importance['importance'])):\n",
    "    ax.text(val + 0.002, i, f'{val:.4f}', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. R√©sum√© et Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©sum√© complet\n",
    "print('='*70)\n",
    "print('R√âSUM√â DU MOD√àLE DE PR√âDICTION DES MALADIES CARDIOVASCULAIRES')\n",
    "print('='*70)\n",
    "\n",
    "print('\\nüìä DONN√âES:')\n",
    "print(f'  ‚Ä¢ Taille totale: {len(df):,} patients')\n",
    "print(f'  ‚Ä¢ Nombre de features: {X.shape[1]}')\n",
    "print(f'  ‚Ä¢ Ensemble d\\'entra√Ænement: {len(X_train):,} ({len(X_train)/len(df)*100:.1f}%)')\n",
    "print(f'  ‚Ä¢ Ensemble de test: {len(X_test):,} ({len(X_test)/len(df)*100:.1f}%)')\n",
    "\n",
    "print('\\nü§ñ MOD√àLE:')\n",
    "print(f'  ‚Ä¢ Type: Random Forest Classifier')\n",
    "print(f'  ‚Ä¢ Nombre d\\'arbres: 100')\n",
    "print(f'  ‚Ä¢ Profondeur maximale: 20')\n",
    "print(f'  ‚Ä¢ √âquilibre des classes: Activ√©')\n",
    "\n",
    "print('\\nüìà PERFORMANCE (Ensemble de Test):')\n",
    "print(f'  ‚Ä¢ Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)')\n",
    "print(f'  ‚Ä¢ Precision: {precision:.4f}')\n",
    "print(f'  ‚Ä¢ Recall:    {recall:.4f}')\n",
    "print(f'  ‚Ä¢ F1-Score:  {f1:.4f}')\n",
    "print(f'  ‚Ä¢ ROC-AUC:   {roc_auc:.4f}')\n",
    "\n",
    "print('\\n‚úì VALIDATION CROIS√âE (5-Fold):')  \n",
    "print(f'  ‚Ä¢ Accuracy:  {cv_results[\"test_accuracy\"].mean():.4f} ¬± {cv_results[\"test_accuracy\"].std():.4f}')\n",
    "print(f'  ‚Ä¢ Precision: {cv_results[\"test_precision\"].mean():.4f} ¬± {cv_results[\"test_precision\"].std():.4f}')\n",
    "print(f'  ‚Ä¢ Recall:    {cv_results[\"test_recall\"].mean():.4f} ¬± {cv_results[\"test_recall\"].std():.4f}')\n",
    "print(f'  ‚Ä¢ F1-Score:  {cv_results[\"test_f1\"].mean():.4f} ¬± {cv_results[\"test_f1\"].std():.4f}')\n",
    "print(f'  ‚Ä¢ ROC-AUC:   {cv_results[\"test_roc_auc\"].mean():.4f} ¬± {cv_results[\"test_roc_auc\"].std():.4f}')\n",
    "\n",
    "print('\\nüéØ TOP 5 FEATURES IMPORTANTES:')\n",
    "for idx, (i, row) in enumerate(feature_importance.head(5).iterrows(), 1):\n",
    "    print(f'  {idx}. {row[\"feature\"]:15s} - {row[\"importance\"]:.4f}')\n",
    "\n",
    "print('\\n' + '='*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}